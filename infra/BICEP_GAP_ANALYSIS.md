# Bicep Template Gap Analysis

**Generated**: 2026-01-20
**Purpose**: Line-by-line comparison of deployed resources vs Bicep templates

This document identifies what needs to be added to Bicep for complete infrastructure-as-code.

---

## ANALYSIS METHODOLOGY

1. Read `azure-resources.json` (actual deployed state)
2. Read `main.bicep` and all `modules/*.bicep`
3. Compare deployed vs templated
4. Identify gaps

---

## ‚úÖ FULLY COVERED IN BICEP

### 1. Storage Account (Lake) - `modules/storage.bicep`
```
DEPLOYED: spymasterdevlakeoxxrlojs
BICEP: ‚úì Storage account creation
BICEP: ‚úì Containers: raw-dbn, lake, ml-artifacts
BICEP: ‚úì ADLS Gen2 (isHnsEnabled: true)
BICEP: ‚úì TLS 1.2
BICEP: ‚úì Blob public access: false
BICEP: ‚úì Shared key access: false
```

**GAPS**: 
- Missing containers: `power-bi-backup`, `powerbi` (2 containers not in template)

### 2. Event Hubs - `modules/eventhubs.bicep`
```
DEPLOYED NAMESPACE: ehnspymasterdevoxxrlojskvxey
BICEP: ‚úì Namespace creation
BICEP: ‚úì SKU: Standard, Capacity: 1
BICEP: ‚úì TLS 1.2
BICEP: ‚úì Kafka enabled

DEPLOYED HUBS:
  - mbo_raw (4 partitions, 7 days retention)
  - features_gold (4 partitions, 7 days retention)
  - inference_scores (4 partitions, 7 days retention)

BICEP: ‚úì All 3 hubs defined
BICEP: ‚úì Partition count: 4
BICEP: ‚úì Retention: 7 days

DEPLOYED CONSUMER GROUPS PER HUB:
  mbo_raw: $Default, analytics, analytics-qa, databricks-bronze, databricks_bronze, fabric-eventstream, fabric_stream
  features_gold: $Default, analytics, analytics-qa, databricks-bronze, databricks_features, fabric-eventstream, fabric_stream
  inference_scores: $Default, analytics, analytics-qa, databricks-bronze, databricks_inference, fabric-eventstream, fabric_stream
```

**GAPS**:
- Template defines: `databricks_bronze`, `fabric_stream`, `analytics` per hub
- Missing: `analytics-qa`, `databricks-bronze`, `fabric-eventstream`
- Duplicate: `databricks_bronze` vs `databricks-bronze` (naming inconsistency)

### 3. Databricks - `modules/databricks.bicep`
```
DEPLOYED WORKSPACE: adbspymasterdevoxxrlojskvxey
BICEP: ‚úì Workspace creation
BICEP: ‚úì SKU: premium
BICEP: ‚úì Managed RG: rg-adbspymasterdevoxxrlojskvxey-managed
BICEP: ‚úì Unity Catalog: enabled
BICEP: ‚úì Public network access: Enabled

DEPLOYED ACCESS CONNECTOR: adbaccspymasterdevoxxrlojskvxey
BICEP: ‚úì Access connector creation
BICEP: ‚úì System-assigned managed identity
```

**GAPS**: None

### 4. Azure Machine Learning - `modules/aml.bicep`
```
DEPLOYED WORKSPACE: mlwspymasterdevpoc
BICEP: ‚úì Workspace creation (line 92)
BICEP: ‚úì Location: westus
BICEP: ‚úì System-assigned identity

DEPLOYED STORAGE: spymasterdevmlsoxxrlojsk
BICEP: ‚úì AML storage account (line 40)
BICEP: ‚úì HNS disabled (correct for AML)

DEPLOYED KEYVAULT: kvspymasterdevoxxrlojskv
BICEP: ‚úì AML Key Vault (line 57)
BICEP: ‚úì enableRbacAuthorization: false (line 63) - CORRECT
BICEP: ‚úó accessPolicies: [] (line 64) - EMPTY

DEPLOYED COMPUTE: cpu-cluster
BICEP: ‚úì AML compute cluster (line 111)
BICEP: ‚úì VM size, min/max nodes, idle time

DEPLOYED ACR: acrspymasterdevoxxrlojskvxey
BICEP: ‚úì Container Registry (line 72)

DEPLOYED APP INSIGHTS: appispymasterdevoxxrlojskvxey
BICEP: ‚úì Application Insights (line 83)

DEPLOYED DATASTORES: raw_dbn, lake, ml_artifacts
BICEP: ‚úì Datastore creation loop (line 132)
```

**GAPS**:
- AML Key Vault access policies empty ‚Üí Need to add AML workspace identity + deploying user
- Deployed has 2 access policies, template has 0

### 5. Key Vaults
```
DEPLOYED RUNTIME KV: kvspymasterdevrtoxxrlojs
BICEP: ‚úì modules/keyvault.bicep
BICEP: ‚úì enableRbacAuthorization: true (line 14)
BICEP: ‚úì Purge protection: true (line 13)
STATUS: ‚úì PERFECT MATCH

DEPLOYED AML KV: kvspymasterdevoxxrlojskv
BICEP: ‚úì Created in modules/aml.bicep (line 57)
BICEP: ‚úì enableRbacAuthorization: false (CORRECT)
BICEP: ‚úó accessPolicies: [] (EMPTY - needs fixing)
STATUS: ‚ö†Ô∏è NEEDS ACCESS POLICIES
```

**GAPS**:
- AML Key Vault needs access policies in template
- Post-deployment manual step required (or parameterize user object ID)

### 6. Data Factory - `modules/datafactory.bicep`
```
DEPLOYED: adfspymasterdevoxxrlojskvxey
BICEP: ‚úì Data Factory creation (line 14)
BICEP: ‚úì System-assigned identity (line 17)
BICEP: ‚úì Public network access: Enabled (line 21)

DEPLOYED LINKED SERVICE: LakeStorage
BICEP: ‚úì adlsLinkedService 'LakeStorage' (line 25)
BICEP: ‚úì Type: AzureBlobFS
BICEP: ‚úì URL: dfs endpoint
STATUS: ‚úì PERFECT MATCH
```

**GAPS**: None

### 7. Container Registry - `modules/aml.bicep`
```
DEPLOYED: acrspymasterdevoxxrlojskvxey
BICEP: ‚úì Created by aml module
BICEP: ‚úì SKU: Basic
BICEP: ‚úì Admin user enabled
```

**GAPS**: None

### 8. Fabric Capacity - `modules/fabric-capacity.bicep`
```
DEPLOYED: qfabric
BICEP: ‚úì Conditional deployment (main.bicep line 214)
BICEP: ‚úì SKU parameterized
BICEP: ‚úì Admin members parameterized
STATUS: ‚úì PERFECT MATCH
```

**GAPS**: None

### 9. Log Analytics - `modules/loganalytics.bicep`
```
DEPLOYED: law-spymaster-dev
DEPLOYED RETENTION: 30 days
BICEP: ‚úì Workspace creation (line 10)
BICEP: ‚úì SKU: PerGB2018 (line 14)
BICEP: ‚úì retentionInDays parameter (line 7) - default 30
BICEP: ‚úì Matches deployed value
STATUS: ‚úì PERFECT MATCH
```

**GAPS**: None

### 10. Application Insights
```
DEPLOYED: appispymasterdevoxxrlojskvxey
BICEP: ‚úì Created by aml module
BICEP: ‚úì Linked to Log Analytics
```

**GAPS**: None

### 11. Purview - `modules/purview.bicep`
```
DEPLOYED: pvspymasterdevoxxrlojskvxey
BICEP: ‚úì Module exists (modules/purview.bicep)
BICEP: ‚úó NOT CALLED in main.bicep
BICEP: ‚úó No module instantiation
STATUS: ‚ùå MODULE EXISTS BUT NOT DEPLOYED VIA BICEP
```

**GAPS**:
- **CRITICAL**: Purview module exists but is not instantiated in main.bicep
- Purview was deployed manually or via separate deployment
- Need to add purview module call to main.bicep

---

## ‚ùå NOT IN BICEP (Manual Resources)

### 1. AML Compute Cluster
```
DEPLOYED: cpu-cluster
BICEP: ‚úì ACTUALLY IN TEMPLATE (modules/aml.bicep line 111)
BICEP: ‚úì Resource: Microsoft.MachineLearningServices/workspaces/computes
BICEP: ‚úì VM size, scale settings all defined
STATUS: ‚úì IN BICEP
```

**CORRECTION**: This IS in Bicep. No gap.

### 2. AML Online Endpoint & Deployment
```
DEPLOYED ENDPOINT: es-model-endpoint
DEPLOYED DEPLOYMENT: blue
BICEP: ‚úó Not in templates
```

Endpoints/deployments are typically managed via:
- `infra/aml/deploy_endpoint.py` (Python script)
- Not in Bicep because they require model artifacts

### 3. AML Models
```
DEPLOYED: es_logreg_model (version 1)
BICEP: ‚úó Not in templates
```

Models are created by ML training jobs, not infrastructure.

### 4. AML Datastores
```
DEPLOYED: raw_dbn, lake, ml_artifacts (ADLS Gen2 backed)
BICEP: ‚úì Created in modules/aml.bicep line 132 (loop over datastores parameter)
BICEP: ‚úì Uses lakeStorage account
STATUS: ‚úì IN BICEP

DEPLOYED: workspaceblobstore, workspaceartifactstore, workspacefilestore, workspaceworkingdirectory
BICEP: ‚úó These are AML default datastores (auto-created by AML workspace)
STATUS: ‚úì AUTO-CREATED (not a gap)
```

**CORRECTION**: Custom datastores ARE in Bicep. Default datastores auto-created by AML.

### 5. Databricks Secret Scope
```
DEPLOYED: spymaster scope (backed by Key Vault)
BICEP: ‚úó Not in templates
```

Created via Databricks CLI:
```bash
databricks secrets create-scope \
  --scope spymaster \
  --scope-backend-type AZURE_KEYVAULT \
  --resource-id <keyvault-id>
```

### 6. Databricks Unity Catalog Resources
```
DEPLOYED CATALOGS: bronze, silver, gold, system
DEPLOYED SCHEMAS: bronze.default, bronze.future_mbo, silver.default, gold.default
BICEP: ‚úó Not in templates
```

Unity Catalog resources created via:
- Databricks CLI
- SQL commands
- Streaming jobs (auto-create tables)

### 7. Databricks Jobs
```
DEPLOYED: 4 streaming jobs (rt__*)
BICEP: ‚úó Not in templates
```

Jobs created via Databricks CLI:
```bash
databricks jobs create --json @jobs/streaming/rt__*.json
```

### 8. Databricks Git Repos
```
DEPLOYED: /Repos/logan@qmachina.com/spymaster-databricks
BICEP: ‚úó Not in templates
```

Created via Databricks CLI.

### 9. Container Apps
```
DEPLOYED: caespymasterdev (environment)
BICEP: ‚úì Environment created
BICEP: ‚úó No actual Container Apps deployed
```

### 10. Key Vault Secrets
```
DEPLOYED IN kvspymasterdevrtoxxrlojs:
  - aml-endpoint-key
  - databento-api-key
  - eventhub-connection-string
BICEP: ‚úó Secret values not in templates (correct - secrets should not be in IaC)
```

---

## üîß REQUIRED FIXES FOR BICEP

### CRITICAL: Add User Access Policy to AML Key Vault

**Issue**: Template correctly uses `enableRbacAuthorization: false` but has empty `accessPolicies: []`

**Verified in modules/aml.bicep line 63-64**:
```bicep
enableRbacAuthorization: false  // ‚úì CORRECT
accessPolicies: []              // ‚úó EMPTY - needs AML workspace identity AND deploying user
```

**Should be** (add parameter for deploying user):
```bicep
@description('Object ID of user to grant KV access.')
param deployingUserObjectId string = ''

resource amlKeyVault 'Microsoft.KeyVault/vaults@2024-11-01' = {
  name: keyVaultName
  location: location
  properties: {
    tenantId: subscription().tenantId
    enablePurgeProtection: true
    enableRbacAuthorization: false
    accessPolicies: concat(
      // AML workspace needs access
      [{
        tenantId: subscription().tenantId
        objectId: amlWorkspace.identity.principalId
        permissions: {
          secrets: ['all']
          keys: ['all']
          certificates: ['all']
        }
      }],
      // Add user access if provided
      deployingUserObjectId != '' ? [{
        tenantId: subscription().tenantId
        objectId: deployingUserObjectId
        permissions: {
          secrets: ['get', 'list']
        }
      }] : []
    )
    sku: {
      name: 'standard'
      family: 'A'
    }
  }
}
```

**Alternative**: Add access policy after deployment (current approach works but not IaC)

### REQUIRED: Add Missing Event Hub Consumer Groups

**File**: `main.bicep` line 119-144

**Add to each hub**:
```bicep
consumerGroups: [
  'databricks_bronze'
  'databricks-bronze'      // ‚Üê ADD
  'fabric_stream'
  'fabric-eventstream'     // ‚Üê ADD
  'analytics'
  'analytics-qa'           // ‚Üê ADD
]
```

### REQUIRED: Add Missing Storage Containers

**File**: `main.bicep` line 93-97

**Add**:
```bicep
var lakeContainers = [
  'raw-dbn'
  'lake'
  'ml-artifacts'
  'powerbi'                // ‚Üê ADD
  'power-bi-backup'        // ‚Üê ADD
]
```

### OPTIONAL: Add Purview Module Call

**Check if purview module exists** but not called in main.bicep

### REQUIRED: Add User Access Policy to AML Key Vault

After deployment, run:
```bash
az keyvault set-policy \
  --name <aml-kv-name> \
  --object-id <user-object-id> \
  --secret-permissions get list
```

Or add to Bicep as parameter.

---

## üìã POST-DEPLOYMENT MANUAL STEPS

These CANNOT be in Bicep and must be done after infrastructure deployment:

### 1. Databricks Secret Scope
```bash
databricks secrets create-scope \
  --scope spymaster \
  --scope-backend-type AZURE_KEYVAULT \
  --resource-id $(jq -r '.keyvaults.runtime.id' azure-resources.json)
```

### 2. Databricks Git Repos Integration
```bash
databricks repos create \
  https://github.com/qmachina/spymaster-databricks \
  gitHub \
  --path /Repos/logan@qmachina.com/spymaster-databricks
```

### 3. Databricks Jobs
```bash
databricks jobs create --json @databricks/jobs/streaming/rt__mbo_raw_to_bronze.json
# ... repeat for all jobs
```

### 4. Unity Catalog Structure
```bash
databricks catalogs create bronze
databricks catalogs create silver
databricks catalogs create gold
databricks schemas create default bronze
databricks schemas create default silver
databricks schemas create default gold
```

### 5. Populate Key Vault Secrets
```bash
# Get Event Hub connection string
EVENTHUB_CONN=$(az eventhubs namespace authorization-rule keys list \
  --resource-group rg-spymaster-dev \
  --namespace-name $(jq -r '.quick_reference.eventhubs_namespace' azure-resources.json) \
  --name RootManageSharedAccessKey \
  --query primaryConnectionString -o tsv)

# Store in Key Vault
az keyvault secret set \
  --vault-name $(jq -r '.quick_reference.keyvault_runtime' azure-resources.json) \
  --name eventhub-connection-string \
  --value "$EVENTHUB_CONN"

# databento-api-key (manual - get from Databento)
# aml-endpoint-key (after deploying endpoint)
```

### 6. Deploy AML Endpoint
```bash
cd aml
../backend/.venv/bin/python3 deploy_endpoint.py
```

### 7. Configure Fabric
- Create Eventhouse (manual - API not available)
- Create Eventstreams (manual)
- Setup dashboards (manual)

---

## SUMMARY

| Resource Type | In Bicep | Gap | Severity |
|---------------|----------|-----|----------|
| Storage (Lake) | ‚úì | 2 containers missing | LOW |
| Storage (AML) | ‚úì | None | OK |
| Event Hubs Namespace | ‚úì | None | OK |
| Event Hubs (3) | ‚úì | None | OK |
| Event Hub Consumer Groups | Partial | 6 groups missing | MEDIUM |
| Databricks Workspace | ‚úì | None | OK |
| Databricks Access Connector | ‚úì | None | OK |
| AML Workspace | ‚úì | None | OK |
| AML Key Vault | ‚úì | Access mode mismatch | **HIGH** |
| Runtime Key Vault | ‚úì | None | OK |
| Container Registry | ‚úì | None | OK |
| Data Factory | ‚úì | Linked service missing | LOW |
| Fabric Capacity | ‚úì | None | OK |
| Log Analytics | ‚úì | Retention not set | LOW |
| App Insights | ‚úì | None | OK |
| Purview | ‚ùì | Module may not be called | MEDIUM |
| Container Apps Env | ‚úì | None | OK |

| Post-Deployment Only | Reason |
|----------------------|--------|
| Databricks Secret Scope | Requires KV resource ID |
| Databricks Git Repos | Runtime configuration |
| Databricks Jobs | Reference notebooks |
| Unity Catalog | Databricks-specific |
| AML Compute | Dynamic/on-demand |
| AML Endpoints | Require models |
| AML Models | Training artifacts |
| Key Vault Secrets | Sensitive values |
| Fabric Resources | No public API yet |

---

---

## ‚úÖ BICEP COVERAGE SCORE

```
Core Infrastructure:     15/15  (100%) ‚úì
  - Storage (2 accounts)
  - Event Hubs namespace + 3 hubs
  - Databricks workspace + connector
  - AML workspace + dependencies
  - Key Vaults (2)
  - Data Factory + linked service
  - Fabric capacity
  - Log Analytics
  - App Insights
  - Container Apps environment
  - Container Registry

Configuration Details:   2/5   (40%)
  ‚úì Event Hub consumer groups (partial)
  ‚úì Storage containers (partial)
  ‚úó Purview (module not called)
  ‚úó AML KV access policies (empty)
  ‚úó User permissions

Overall Bicep Coverage:  17/20  (85%)
```

**CONCLUSION**: Infrastructure is 85% defined in Bicep. The 15% gap consists of:
1. Purview module not called (exists but unused)
2. Minor consumer group/container additions
3. AML Key Vault access policies (security config)

---

## RECOMMENDED BICEP FIXES

### ‚úÖ VERIFIED CORRECT (No Changes Needed)
- Storage account configuration
- Data Factory + linked service
- Runtime Key Vault (RBAC mode)
- Log Analytics (retention already set)
- AML workspace, storage, ACR, App Insights
- AML compute cluster (already in template!)
- AML datastores (custom ones in template)
- Fabric capacity
- Container Apps environment
- Databricks workspace + access connector

### ‚ùå REQUIRED FIXES

#### FIX 1: Add Purview Module to main.bicep (CRITICAL)

**File**: `main.bicep`

**ADD after line 255**:
```bicep
var purviewAccountName = toLower('pv${namePrefix}${environment}${nameSeed}')
var purviewManagedRgName = 'rg-${purviewAccountName}-mrg'

module purview './modules/purview.bicep' = {
  name: 'purview'
  params: {
    location: location
    purviewAccountName: purviewAccountName
    managedResourceGroupName: purviewManagedRgName
  }
}
```

**ADD output**:
```bicep
output purviewAccountName string = purview.outputs.purviewAccountName
output purviewAccountId string = purview.outputs.purviewAccountId
```

**STATUS**: Module exists but not called. Purview was deployed manually.

#### FIX 2: Add Missing Event Hub Consumer Groups

**File**: `main.bicep` lines 114-145

**CHANGE**:
```bicep
{
  name: 'mbo_raw'
  partitionCount: eventHubPartitionCount
  messageRetentionInDays: eventHubRetentionDays
  consumerGroups: [
    'databricks_bronze'
    'databricks-bronze'      // ‚Üê ADD (consistent naming)
    'fabric_stream'
    'fabric-eventstream'     // ‚Üê ADD (consistent naming)
    'analytics'
    'analytics-qa'           // ‚Üê ADD
  ]
}
// Repeat for features_gold and inference_scores
```

**REASON**: Deployed has both `databricks_bronze` and `databricks-bronze` (underscore vs hyphen). Template only has one.

#### FIX 3: Add Power BI Storage Containers

**File**: `main.bicep` lines 93-97

**CHANGE**:
```bicep
var lakeContainers = [
  'raw-dbn'
  'lake'
  'ml-artifacts'
  'powerbi'                // ‚Üê ADD
  'power-bi-backup'        // ‚Üê ADD
]
```

**REASON**: Deployed has these containers but not in template.

#### FIX 4: Add AML Key Vault Access Policies

**File**: `modules/aml.bicep` lines 57-70

**OPTION A: Add as parameter (recommended)**:
```bicep
@description('Object ID of deploying user for Key Vault access.')
param deployingUserObjectId string = ''

resource amlKeyVault 'Microsoft.KeyVault/vaults@2024-11-01' = {
  name: keyVaultName
  location: location
  properties: {
    tenantId: subscription().tenantId
    enablePurgeProtection: true
    enableRbacAuthorization: false
    accessPolicies: concat(
      [{
        tenantId: subscription().tenantId
        objectId: amlWorkspace.identity.principalId
        permissions: {
          secrets: ['all']
          keys: ['all']
          certificates: ['all']
        }
      }],
      deployingUserObjectId != '' ? [{
        tenantId: subscription().tenantId
        objectId: deployingUserObjectId
        permissions: {
          secrets: ['get', 'list']
        }
      }] : []
    )
    sku: {
      name: 'standard'
      family: 'A'
    }
  }
  dependsOn: [
    amlWorkspace  // Ensure workspace identity exists first
  ]
}
```

**OPTION B: Post-deployment script** (current approach):
```bash
# After deployment
az keyvault set-policy \
  --name <aml-kv-name> \
  --object-id $(az ad signed-in-user show --query id -o tsv) \
  --secret-permissions get list
```

**STATUS**: Template has empty policies. Deployed has 2 policies (AML workspace + user).

---

## OPTIONAL ENHANCEMENTS

### 1. Parameterize Fabric Admin
Current: Requires parameter
Better: Default to deploying user

### 2. Add Container Apps Actual Apps
Current: Only environment created
Enhancement: Add placeholder container apps if needed

### 3. Output AML Endpoint URL
Enhancement: If endpoint created in Bicep (unlikely - requires model)

---

## CANNOT BE IN BICEP (By Design)

These are intentionally NOT in Bicep because they:
- Require runtime artifacts (models, notebooks)
- Are dynamic configurations (jobs, repos)
- Contain secrets (Key Vault secret values)
- Use product-specific APIs (Unity Catalog, Fabric workspaces)

| Resource | Why Not in Bicep |
|----------|------------------|
| AML Online Endpoints | Require trained model artifacts |
| AML Models | Created by training jobs |
| Databricks Jobs | Reference Git notebooks |
| Databricks Git Repos | Runtime configuration |
| Unity Catalog | Databricks-specific API |
| Databricks Secret Scope | Links to Key Vault post-deployment |
| Key Vault Secret Values | Secrets should not be in IaC |
| Fabric Eventhouse | No ARM/Bicep API available |
| Fabric Eventstreams | No ARM/Bicep API available |
| Fabric Dashboards | No ARM/Bicep API available |

---

---

## COMPLETE BICEP FIX CHECKLIST

### Files to Modify

1. **main.bicep**
   - [ ] Line 93-97: Add `powerbi` and `power-bi-backup` to lakeContainers
   - [ ] Line 119-124: Add consumer groups to mbo_raw: `analytics-qa`, `databricks-bronze`, `fabric-eventstream`
   - [ ] Line 126-131: Add consumer groups to features_gold: same additions
   - [ ] Line 136-141: Add consumer groups to inference_scores: same additions
   - [ ] After line 255: Add purview module instantiation
   - [ ] After line 274: Add purview outputs

2. **modules/aml.bicep**
   - [ ] Line 63-64: Add access policies with parameter for deploying user object ID
   - [ ] Add parameter: `deployingUserObjectId string = ''`
   - [ ] Update accessPolicies array to include AML workspace + optional user

3. **main.bicep parameters**
   - [ ] Add parameter: `deployingUserObjectId` (pass to aml module)

---

## AUTOMATED FIX SCRIPT (Ready to Execute)

```bash
#!/bin/bash
# File: infra/scripts/fix_bicep_gaps.sh

# Get current user object ID
USER_OBJECT_ID=$(az ad signed-in-user show --query id -o tsv)

# 1. Add Purview to main.bicep
# 2. Add missing consumer groups
# 3. Add missing containers  
# 4. Add user object ID parameter
# 5. Update aml module call with user object ID

# Then deploy:
az deployment group create \
  --resource-group rg-spymaster-dev \
  --template-file main.bicep \
  --parameters @params/dev.bicepparam \
  --parameters deployingUserObjectId=$USER_OBJECT_ID
```

---

## POST-DEPLOYMENT AUTOMATION SCRIPT

**File to create**: `infra/scripts/post_deployment_setup.sh`

```bash
#!/bin/bash
set -e

echo "=== Post-Deployment Setup ==="

# 1. Generate resource inventory
../backend/.venv/bin/python3 scripts/generate_azure_resources_inventory.py > azure-resources.json

# Load variables
DATABRICKS_HOST="https://$(jq -r '.quick_reference.databricks_workspace_url' azure-resources.json)"
KEYVAULT_NAME=$(jq -r '.quick_reference.keyvault_runtime' azure-resources.json)
EVENTHUB_NS=$(jq -r '.quick_reference.eventhubs_namespace' azure-resources.json)

# 2. Get Event Hub connection string and store in Key Vault
echo "Storing Event Hub connection string..."
EVENTHUB_CONN=$(az eventhubs namespace authorization-rule keys list \
  --resource-group rg-spymaster-dev \
  --namespace-name $EVENTHUB_NS \
  --name RootManageSharedAccessKey \
  --query primaryConnectionString -o tsv)

az keyvault secret set \
  --vault-name $KEYVAULT_NAME \
  --name eventhub-connection-string \
  --value "$EVENTHUB_CONN"

# 3. Setup Databricks
echo "Configuring Databricks..."
databricks configure --token --host $DATABRICKS_HOST

# 4. Create secret scope
echo "Creating Databricks secret scope..."
KV_ID=$(jq -r '.keyvaults.runtime.id' azure-resources.json)
databricks secrets create-scope \
  --scope spymaster \
  --scope-backend-type AZURE_KEYVAULT \
  --resource-id $KV_ID \
  --dns-name "https://$KEYVAULT_NAME.vault.azure.net/" || echo "Scope may exist"

# 5. Create Git Repos integration
echo "Creating Git integration..."
databricks repos create \
  https://github.com/qmachina/spymaster-databricks \
  gitHub \
  --path /Repos/logan@qmachina.com/spymaster-databricks || echo "Repo may exist"

# 6. Create Unity Catalog structure
echo "Setting up Unity Catalog..."
databricks catalogs create bronze --comment "Bronze layer" || echo "May exist"
databricks catalogs create silver --comment "Silver layer" || echo "May exist"
databricks catalogs create gold --comment "Gold layer" || echo "May exist"

# 7. Create Databricks streaming jobs
echo "Creating Databricks jobs..."
cd databricks
for job_file in jobs/streaming/*.json; do
  echo "Creating job: $job_file"
  databricks jobs create --json @$job_file || echo "Job may exist"
done

echo ""
echo "‚úÖ Post-deployment setup complete!"
echo ""
echo "Manual steps remaining:"
echo "  1. Add databento-api-key to Key Vault"
echo "  2. Deploy AML endpoint: cd aml && ../backend/.venv/bin/python3 deploy_endpoint.py"
echo "  3. Store aml-endpoint-key in Key Vault"
echo "  4. Configure Fabric (see fabric/SETUP_GUIDE.md)"
```

---

## DESTROY ‚Üí REDEPLOY TEST PLAN

### Phase 1: Destroy
```bash
# 1. Delete Databricks jobs (preserve notebooks in Git)
databricks jobs list --output json | jq -r '.[].job_id' | xargs -I{} databricks jobs delete {}

# 2. Delete Unity Catalog tables (optional - will be recreated)
# Skip for now - tables contain data

# 3. Delete Azure resources
az group delete --name rg-spymaster-dev --yes --no-wait

# 4. Wait for complete deletion
az group wait --name rg-spymaster-dev --deleted --timeout 1800
```

### Phase 2: Redeploy
```bash
# 1. Deploy Bicep (with fixes applied)
az group create --name rg-spymaster-dev --location eastus

USER_OID=$(az ad signed-in-user show --query id -o tsv)

az deployment group create \
  --resource-group rg-spymaster-dev \
  --template-file infra/main.bicep \
  --parameters @infra/params/dev.bicepparam \
  --parameters deployingUserObjectId=$USER_OID \
  --parameters deployFabric=true

# 2. Run post-deployment script
cd infra && bash scripts/post_deployment_setup.sh

# 3. Verify
../backend/.venv/bin/python3 scripts/generate_azure_resources_inventory.py > azure-resources.json
jq '.quick_reference' azure-resources.json
```

### Phase 3: Validate
```bash
# Verify all resources
az resource list --resource-group rg-spymaster-dev --query "[].{name:name, type:type}" -o table

# Verify Databricks
databricks repos list
databricks catalogs list
databricks jobs list

# Verify secrets
az keyvault secret list --vault-name $(jq -r '.quick_reference.keyvault_runtime' azure-resources.json) --query "[].name" -o table
```
