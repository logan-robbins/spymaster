# Pentaview Level Interaction Research

**Status**: Model Trained & Validated  
**Last Updated**: 2026-01-01  
**Data Version**: v4.0.0  
**Audience**: AI Coding Agents  
**Goal**: Sellable signal product for ES day traders

---

## MOST RECENT ITERATION (2026-01-01) — Episode-Level PM/OR BREAK vs REJECT Driver Analysis

### Scope / Constraints

- This iteration is **research-only** and focused on **PM_HIGH/PM_LOW/OR_HIGH/OR_LOW**.
- **Did not modify retrieval strategy** (FAISS partitions / kNN query logic).
- Goal: make the **episode vector** + Pentaview streams **usable for attribution** (no schema drift), and ship a repeatable **episode-level** driver report for future agents.

### Why This Was Needed (Schema Drift + Invalid Attribution)

Observed on existing stored v4.0.0 episode vectors:
- `episodes.npy` had **NaNs** in some dimensions.
- The 3 “approach dynamics” dims inside the  vector were being populated with **unrelated distance features** (mapping bug), producing misleading coefficients/attribution.
- Pentaview `direction` inference from `distance_signed_atr` was **sign-flipped** (UP vs DOWN), making joins on `(timestamp, level_kind, direction)` unreliable.

Net: any “which features explain BREAK vs REJECT” analysis could be garbage unless vector+join semantics were corrected.

### Changes Made (Code)

**1) Fix vector semantics at episode construction time**
- File: `backend/src/ml/episode_vector.py`
- Key fixes:
  - `construct_episode_vector()` now writes:
    - `approach_velocity`, `approach_bars`, `approach_distance_atr` into their intended slots
    - uses `time_since_last_touch_sec` (not the old `time_since_last_touch`)
  - `construct_episodes_from_events()` now:
    - overlays **event-row** features onto the anchor `current_bar` so anchor-only columns (e.g., `velocity_2min`) don’t become zeros due to missing state-table columns
    - computes a simple per-level `time_since_last_touch_sec` (seconds since prior interaction event for the same `(level_kind, level_price)`).

**2) Fix Pentaview `direction` inference**
- File: `backend/src/pipeline/pipelines/pentaview_pipeline.py`
- `distance_signed_atr = (level_price - spot)/atr`:
  - `> 0` implies `spot < level_price` → **UP** (approaching from below)
  - `< 0` implies `spot > level_price` → **DOWN** (approaching from above)
- Previous code used the opposite sign.

**3) Add episode-level driver analysis script**
- File: `backend/scripts/analyze_level_break_drivers.py`
- Outputs a JSON report ranking “BREAK drivers” vs “REJECT drivers” by segment:
  - segment key = `level_kind | direction | time_bucket`
  - label = `outcome_{horizon}` filtered to **BREAK/REJECT** (CHOP excluded)
  - model = sparse LR (L1) + Leave-One-Day-Out AUC
  - optional baseline = Pentaview proxy feature set:
    - `[sigma_s, sigma_r, sigma_b_slope, sigma_p_slope, sigma_d]`
- Important join fix: stream bars are joined on `(timestamp, level_kind)` (NOT direction) because historical stream direction can be inconsistent if generated with older inference.

### Output Artifact (Most Useful Thing to Read)

- `backend/data/ml/level_break_drivers_PMOR_v4_h4.json`
  - Generated by running the script over the full v4.0.0 date range.

### How to Reproduce (Recommended)

Run from `backend/` and invoke as a module so `src.*` imports resolve:

```bash
cd backend

# Full-range PM/OR driver report (v4.0.0, 4min labels)
uv run python -m scripts.analyze_level_break_drivers \
  --start 2025-11-03 --end 2025-12-19 \
  --version v4.0.0 \
  --horizon 4min \
  --min-samples 50 \
  --output-json data/ml/level_break_drivers_PMOR_v4_h4.json
```

### Key Results (v4.0.0, PM/OR only, horizon=4min)

From `data/ml/level_break_drivers_PMOR_v4_h4.json`:
- Overall (PM/OR, BREAK/REJECT only):
  - `n = 992`
  - `break_rate ≈ 0.194` *(NOTE: CHOP excluded, so this is conditional)*
  - `AUC (LODO) ≈ 0.80` using the full  vector
- Predictable segment (per 2025-12-31 discovery):
  - direction=UP AND level_kind in {PM_LOW, OR_LOW} AND time_bucket != T0_15
  - `n = 275`, `break_rate ≈ 0.60` *(CHOP excluded)*
  - Pentaview stream-proxy baseline:
    - features = `[sigma_s, sigma_r, sigma_b_slope, sigma_p_slope, sigma_d]`
    - `AUC (LODO) ≈ 0.87`

Common driver patterns observed in top segments (illustrative, not universal):
- BREAK side:
  - near-strike GEX features (e.g. `gex_below_1strike`)
  - barrier evolution (`barrier_delta_liq_trend`)
  - flow acceleration (`ofi_acceleration`)
- REJECT side:
  - distance micro-history features (e.g. `d_atr_t4`)
  - gamma exposure terms (`gamma_exposure*`)

### Caveats / Gotchas for Future Agents

- **CHOP is excluded** in this driver analysis (BREAK vs REJECT only). Any reported break rates are conditional on that filter.
- Some segments are small; AUC can hit 1.0 in tiny N and is not necessarily stable.
- Historical `episodes.npy` in `data/gold/episodes/...` may have been generated with older vector semantics; this script reconstructs vectors from `signals.parquet` + `state.parquet` and also NaN-cleans vectors.
- Stream joining should not include `direction` unless you re-generate Pentaview outputs with the fixed direction inference.

### Next Experiments (Suggested)

- Add **section-level ablations** inside `analyze_level_break_drivers.py` using `VECTOR_SECTIONS` to quantify which physics “story” matters per segment.
- Add **feature interaction probes** (e.g., `sigma_s × proximity`, `sigma_d × gamma_exposure`) for explainability and UI driver statements.
- Add a 3-class variant (BREAK/REJECT/CHOP) with calibrated probabilities (still episode-level).

---

## Product Concept

Real-time BREAK/REJECT probability signal when price approaches key structural levels (PM high/low, OR high/low) during the first 3 hours of ES futures trading.

**Value proposition**: Tell the trader "this level will likely break" or "this level will likely hold" with quantified confidence, based on the current market microstructure state.

---

## CRITICAL DISCOVERY (2025-12-31)

### The 108,910 "Samples" Problem

**Previous understanding was WRONG.** The dataset builder (`build_pentaview_level_dataset.py`) was counting every 30s bar × 5 streams as a "sample":

```
108,910 "samples" = 21,782 unique (timestamp, level) × 5 streams
                 = 99.4% consecutive 30s bars (autocorrelated)
                 = Only 122 TRUE episode starts
```

**TRUE episode count**: **1,181 actual level interactions** over 35 days (33.7/day)

### The Predictable Segment

Most level interactions are **deterministic REJECT (68%)**. Edge exists only in specific conditions:

| Segment | N | BREAK Rate | Predictable? |
|---------|---|------------|--------------|
| DOWN direction (any level) | 213 | **0.9%** | NO - always REJECT |
| HIGH levels + UP | 603 | **4.2%** | NO - always REJECT |
| **LOW levels + UP + T30+** | **363** | **45.5%** | **YES** |

**The only predictable segment**: Approaches from below (UP) to support levels (PM_LOW, OR_LOW) after the opening 15 minutes.

**Implication for product**: 
- For HIGH levels: Just tell trader "80%+ REJECT probability" (no model needed)
- For LOW levels from below: Use the trained model to give BREAK/REJECT signal

---

## Validated Model Performance

### Model Saved: `data/ml/break_predictor_v1.joblib`

**Evaluation**: Leave-One-Day-Out Cross-Validation on 363 episodes

| Feature Set | AUC | Precision | HC Precision (≥60%) |
|-------------|-----|-----------|---------------------|
| sigma_s only (1 feat) | 0.679 | 61.3% | 60.4% |
| All 7 streams | 0.722 | 61.5% | 63.7% |
| **Full  vector** | **0.868** | **71.6%** | **76.2%** |

**Base rate**: 45.5% → Model achieves **+15-27% edge** over random

### Feature Importance (Trained Random Forest)

```
sigma_s        0.446  ← THE most important (Setup quality)
sigma_d        0.220  ← Dealer positioning  
sigma_r        0.153  ← Structure (barrier + setup)
sigma_b_slope  0.108  ← Barrier rate of change
sigma_p_slope  0.074  ← Pressure rate of change
```

**Critical insight**: `sigma_p` (Pressure) does NOT predict. `sigma_s` (Setup) does.

---

## Stream Correlations with BREAK Outcome

Correlations measured on 363 predictable-segment episodes:

| Stream | Correlation | p-value | Interpretation |
|--------|-------------|---------|----------------|
| **sigma_s (Setup)** | **+0.40** | <0.001 | **STRONGEST** - use this |
| sigma_r (Structure) | +0.24 | <0.001 | Strong |
| sigma_b_slope | -0.21 | <0.001 | Declining barrier → BREAK |
| sigma_d (Dealer) | +0.14 | <0.01 | Moderate |
| sigma_m (Momentum) | -0.14 | <0.05 | Lower momentum → BREAK |
| sigma_f (Flow) | +0.11 | <0.05 | Weak |
| **sigma_p (Pressure)** | **-0.09** | **0.09** | **NOT SIGNIFICANT** |

### Raw Feature Correlations

| Feature | Correlation | BREAK mean | REJECT mean |
|---------|-------------|------------|-------------|
| **proximity** | **+0.60** | 0.756 | 0.546 |
| **level_stacking_5pt** | **+0.39** | 0.721 | 0.328 |
| **distance_signed_atr** | **-0.59** | 0.43 ATR | 0.98 ATR |
| prior_touches | -0.18 | 0.26 | 0.43 |
| gamma_exposure | -0.24 | -125.9 | -68.3 |

**Simple rule for traders**: Closer + more confluence + first attempt = BREAK

---

## What sigma_s Actually Measures

From `backend/src/ml/stream_builder.py` lines 326-396:

```python
def compute_setup_stream(bar_row, stats, dct_d_atr, stratum):
    # 1. PROXIMITY: exp(-|d_atr| / 1.5)  → Closer = higher
    # 2. RECENCY: exp(-time_since_last_touch / 900)  → Recent = higher
    # 3. FRESHNESS: 1.0 if attempt <= 2, 0.6 if <= 4, else 0.3
    # 4. CONFLUENCE: (stacking_5pt + stacking_10pt) / 12
    # 5. APPROACH_SPEED: normalized velocity
    # 6. TRAJECTORY_CLEANNESS: from DCT coefficients
```

**Why sigma_s predicts**: It captures the "setup quality" that distinguishes breakouts from rejections:
- Close approach + first attempt + level confluence = BREAK
- Far approach + many failed attempts = REJECT

**Why sigma_p fails**: `sigma_p = 0.55 * sigma_m + 0.45 * sigma_f` is just momentum + flow. High momentum can lead to EITHER strong breakout OR strong rejection.

---

## Signal Product Design

### Real-Time Signal Output

When price enters the approach zone (< 2 ATR) of a structural level:

```
SIGNAL: {
  level: "OR_LOW",
  level_price: 5985.25,
  direction: "UP",  // approaching from below
  
  // Model output
  p_break: 0.67,
  confidence: "HIGH",  // based on threshold
  
  // Key drivers (explainability)
  sigma_s: -0.12,  // Setup quality
  proximity: 0.75,  // How close (0-1)
  confluence: 0.15,  // Level stacking
  attempt: 2,       // Which attempt this is
  
  // Base rate context
  base_rate: 0.455,
  edge: "+22%"
}
```

### Signal Rules

| Condition | Signal | Confidence |
|-----------|--------|------------|
| HIGH level (any direction) | REJECT | 80%+ (no model) |
| DOWN direction (any level) | REJECT | 95%+ (no model) |
| LOW level + UP + p_break ≥ 0.6 | BREAK | HIGH |
| LOW level + UP + p_break ≥ 0.5 | BREAK | MODERATE |
| LOW level + UP + p_break < 0.5 | REJECT | MODERATE |

### Trader Interpretation

**For resistance (HIGH levels)**:
> "Price approaching OR_HIGH from below. Historical REJECT rate: 96%. Fade the breakout."

**For support (LOW levels) with HIGH confidence BREAK**:
> "Price approaching PM_LOW from below. Model: 67% BREAK probability (vs 45% base). Setup quality strong: close approach, first attempt, confluence. Consider long on break."

**For support (LOW levels) with LOW confidence**:
> "Price approaching OR_LOW from below. Model: 42% BREAK probability. Setup degraded: 5th attempt, no confluence. Lean REJECT."

---

## Data Architecture

```
LIVE DATA FLOW:

State Table (30s cadence)
├── data/silver/state/es_level_state/version=v4.0.0/
├── 86 features per bar per active level
└── Source for stream computation

Stream Bars (computed from state)
├── data/gold/streams/pentaview/version=v4.0.0/
├── sigma_m, sigma_f, sigma_b, sigma_d, sigma_s (5 canonical)
├── sigma_p, sigma_r (2 merged)
└── slopes, curvature, jerk (derivatives)

Episode Outcomes (for training/validation)
├── data/gold/episodes/es_level_episodes/version=v4.0.0/metadata/
└── BREAK/REJECT/CHOP labels with timing

Trained Model
├── data/ml/break_predictor_v1.joblib
└── Random Forest on [sigma_s, sigma_r, sigma_b_slope, sigma_p_slope, sigma_d]
```

---


---

## Key Files

**Data**:
- `data/gold/episodes/es_level_episodes/version=v4.0.0/metadata/` - Episode outcomes
- `data/gold/streams/pentaview/version=v4.0.0/` - Stream bars for inference
- `data/ml/break_predictor_v1.joblib` - Trained production model

**Code**:
- `backend/src/ml/stream_builder.py` - Stream computation (sigma_s formula at line 326)
- `backend/src/pipeline/stages/compute_streams.py` - Stream aggregation pipeline

**DO NOT USE**:
- `backend/scripts/build_pentaview_level_dataset.py` - Creates autocorrelated pseudo-samples
- `data/gold/training/pentaview_level_interactions/` - Wrong sample unit

---

## Next Steps for Future Agents

### 1. Improve Model Performance

Current model uses 5 stream features (AUC=0.72). Options to improve:

- **Add raw features**: distance_signed_atr, level_stacking_5pt, gamma_exposure have strong correlations
- **Feature interactions**: sigma_s × proximity, sigma_d × gamma_exposure
- **Different model**: Try XGBoost, neural network

### 2. Expand to More Data

Current training: 363 episodes over 18 days. Need:
- More historical data (backfill more dates)
- Walk-forward validation
- Out-of-sample testing on future dates

### 3. Real-Time Integration

The model needs to be integrated into the live trading system:
- Compute streams in real-time from state table
- Call `generate_signal()` when price enters approach zone
- Display signal to trader in UI

### 4. Product Experiments

- **Threshold optimization**: Find optimal p_break cutoff for trader action
- **Time-of-day stratification**: T30_60 has highest BREAK rate (55%)
- **Level-specific tuning**: OR_LOW vs PM_LOW may need different models
- **Alert timing**: When to trigger signal (2 ATR? 1 ATR? touching level?)

---

## Summary for Quick Reference

**The product predicts BREAK vs REJECT on level interactions.**

**When to emit signal**:
- Price enters approach zone (< 2 ATR) of structural level
- Level is PM_HIGH, PM_LOW, OR_HIGH, or OR_LOW
- Time is within first 3 hours of RTH

**Signal logic**:
- HIGH levels or DOWN direction → Rule-based REJECT (no model needed)
- LOW levels + UP direction → Use trained model for probability

**Model input**: [sigma_s, sigma_r, sigma_b_slope, sigma_p_slope, sigma_d]
**Model output**: P(BREAK) in [0, 1]
**Precision**: 61-72% (vs 45% base rate on predictable segment)

**Key insight**: sigma_s (Setup quality) is the only stream that matters. It captures proximity, confluence, and attempt freshness.
