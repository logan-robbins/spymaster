# Ingestor Module â€” Technical Reference for AI Coding Agents

**Module**: `backend/src/ingestor/`  
**Role**: The Source â€” Data ingestion and normalization layer  
**Architecture Phase**: Phase 2 (Microservices with NATS JetStream)  
**Agent Assignment**: Phase 2 Agent A (PLAN.md Â§13)

---

## Table of Contents

1. [System Architecture Context](#system-architecture-context)
2. [Module Responsibilities](#module-responsibilities)
3. [Files and Ownership](#files-and-ownership)
4. [Data Flow Architecture](#data-flow-architecture)
5. [Event Types and Normalization](#event-types-and-normalization)
6. [NATS Subject Contracts](#nats-subject-contracts)
7. [Vendor Integration](#vendor-integration)
8. [Replay System](#replay-system)
9. [Class Reference](#class-reference)
10. [Entry Points](#entry-points)
11. [Dependencies](#dependencies)
12. [Testing and Validation](#testing-and-validation)
13. [Operational Notes](#operational-notes)

---

## 1. System Architecture Context

### 1.1 Position in the Pipeline

The Ingestor module is the **first stage** in the Spymaster data pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INGESTOR SERVICE (This Module)              â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚   Polygon    â”‚        â”‚   Databento  â”‚                     â”‚
â”‚  â”‚  WebSocket   â”‚        â”‚   DBN Files  â”‚                     â”‚
â”‚  â”‚  (Live Feed) â”‚        â”‚   (Replay)   â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚         â”‚                       â”‚                              â”‚
â”‚         â–¼                       â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚     Normalization & Event Creation       â”‚                 â”‚
â”‚  â”‚  (StockTrade, StockQuote, OptionTrade,   â”‚                 â”‚
â”‚  â”‚   FuturesTrade, MBP10)                   â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                 â”‚                                              â”‚
â”‚                 â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚        NATS JetStream Publisher          â”‚                 â”‚
â”‚  â”‚  Subjects: market.*, levels.*            â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   NATS JetStream      â”‚
              â”‚   (Message Bus)       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  CORE   â”‚    â”‚  LAKE   â”‚    â”‚ GATEWAY â”‚
    â”‚ Service â”‚    â”‚ Service â”‚    â”‚ Service â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Architectural Principles (PLAN.md Â§1)

- **Event-driven ingestion**: Process every trade/quote update immediately (no polling)
- **Vendor normalization**: Convert heterogeneous vendor formats to canonical `event_types.py` dataclasses
- **Time discipline**: All events carry `ts_event_ns` (vendor exchange time) and `ts_recv_ns` (our ingestion time) in Unix nanoseconds UTC
- **NATS as source of truth**: All normalized events are published to NATS JetStream (24-hour retention, file-backed persistence)
- **Replay transparency**: Other services cannot distinguish between live WebSocket feeds and historical DBN replay

---

## 2. Module Responsibilities

### 2.1 Core Functions

1. **Live Feed Ingestion** (`stream_ingestor.py`):
   - Connect to Polygon WebSocket APIs (stocks + options markets)
   - Subscribe to SPY equity (trades + quotes) and SPY 0DTE option trades
   - Dynamic strike management: update option subscriptions as SPY price moves
   - Normalize vendor wire formats to canonical event types

2. **Historical Replay** (`dbn_ingestor.py` + `replay_publisher.py`):
   - Read Databento DBN files (ES futures trades + MBP-10)
   - Stream large files efficiently (iterator pattern, no full file loads)
   - Publish to NATS at configurable replay speed (0x = fast as possible, 1x = realtime, 2x = 2x speed)
   - Merge multiple DBN schemas and dates into unified event-time-ordered stream

3. **NATS Publishing**:
   - Serialize dataclasses to JSON
   - Publish to appropriate NATS JetStream subjects
   - Provide backward compatibility queue mode (transitional, will be removed)

### 2.2 Non-Responsibilities (What This Module Does NOT Do)

- **Storage**: Does not write to Parquet/S3 (Lake Service handles that)
- **State management**: Does not maintain market state (Core Service handles that)
- **Greeks fetching**: Does not poll REST APIs for option greeks (handled separately)
- **Level computation**: Does not compute signals or scores (Core Service handles that)

---

## 3. Files and Ownership

| File | Purpose | Owner | Entry Point |
|------|---------|-------|-------------|
| `main.py` | Service entry point for live ingestion | Phase 2 Agent A | âœ… Yes (standalone) |
| `stream_ingestor.py` | Polygon WebSocket adapter | Phase 2 Agent A | No |
| `dbn_ingestor.py` | Databento DBN file reader | Agent I (storage) | No |
| `replay_publisher.py` | DBN â†’ NATS replay publisher | Phase 2 Agent A | âœ… Yes (standalone) |
| `test_stream.py` | Simple WebSocket connection test | Development | âœ… Yes (dev only) |
| `__init__.py` | Empty (module marker) | N/A | No |

---

## 4. Data Flow Architecture

### 4.1 Live Feed Flow (stream_ingestor.py)

```
Polygon WebSocket    â†’    StreamIngestor    â†’    NATS JetStream    â†’    Consumers
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

T.SPY (stock trades)       normalize           market.stocks.trades      Core/Lake
Q.SPY (stock quotes)       normalize           market.stocks.quotes      Core/Lake
T.O:SPY* (opt trades)      normalize           market.options.trades     Core/Lake
                           + parse ticker
                           + dynamic strikes
```

### 4.2 Replay Flow (replay_publisher.py)

```
DBN Files             â†’    DBNIngestor    â†’    ReplayPublisher    â†’    NATS    â†’    Consumers
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

trades/*.dbn             read_trades()      merge by ts_event_ns    market.futures.trades
MBP-10/*.dbn             read_mbp10()       + apply speed           market.futures.mbp10
                         (iterators)         + publish
```

**Key Insight**: Replay mode publishes to the SAME NATS subjects as live feeds. Downstream services (Core, Lake, Gateway) are replay-agnostic.

---

## 5. Event Types and Normalization

All normalized events are defined in `src/common/event_types.py`. The Ingestor module is responsible for converting vendor wire formats into these canonical dataclasses.

### 5.1 Event Envelope Contract (PLAN.md Â§2.1)

Every event **MUST** include:

| Field | Type | Description |
|-------|------|-------------|
| `ts_event_ns` | `int` | Event time (from vendor) in Unix nanoseconds UTC |
| `ts_recv_ns` | `int` | Receive time (by our system) in Unix nanoseconds UTC |
| `source` | `EventSource` | Enum: `POLYGON_WS`, `DIRECT_FEED`, `REPLAY`, etc. |

### 5.2 Normalized Event Types

#### 5.2.1 StockTrade

**Schema**: `stocks.trades.v1`  
**NATS Subject**: `market.stocks.trades`  
**Source**: Polygon stocks WebSocket `T.SPY`

```python
@dataclass
class StockTrade:
    ts_event_ns: int  # Polygon timestamp * 1_000_000 (ms â†’ ns)
    ts_recv_ns: int   # time.time_ns() at ingestion
    source: EventSource  # EventSource.POLYGON_WS
    symbol: str  # "SPY"
    price: float
    size: int
    exchange: Optional[int] = None
    conditions: Optional[List[int]] = None
    seq: Optional[int] = None  # vendor sequence number
```

**Vendor Wire Format** (Polygon):
```json
{
  "ev": "T",
  "sym": "SPY",
  "x": 4,
  "p": 545.42,
  "s": 100,
  "t": 1715629300123,  // Unix milliseconds
  "c": [12, 37],
  "i": "12345",
  "z": 3
}
```

**Normalization Rules**:
- `ts_event_ns = msg.timestamp * 1_000_000` (ms â†’ ns)
- `ts_recv_ns = time.time_ns()`
- `source = EventSource.POLYGON_WS`

---

#### 5.2.2 StockQuote

**Schema**: `stocks.quotes.v1`  
**NATS Subject**: `market.stocks.quotes`  
**Source**: Polygon stocks WebSocket `Q.SPY`

```python
@dataclass
class StockQuote:
    ts_event_ns: int
    ts_recv_ns: int
    source: EventSource
    symbol: str
    bid_px: float
    ask_px: float
    bid_sz: int  # SHARES (not round lots as of 2025-11-03 per SEC MDI)
    ask_sz: int  # SHARES
    bid_exch: Optional[int] = None
    ask_exch: Optional[int] = None
    seq: Optional[int] = None
```

**Critical Note**: As of **2025-11-03**, Massive/Polygon reports `bid_sz`/`ask_sz` in **SHARES** (not round lots) per SEC MDI rules. See PLAN.md Â§2.4 and [Massive blog post](https://massive.com/blog/change-stocks-quotes-round-lots-to-shares/).

---

#### 5.2.3 OptionTrade

**Schema**: `options.trades.v1`  
**NATS Subject**: `market.options.trades`  
**Source**: Polygon options WebSocket `T.O:SPY*`

```python
@dataclass
class OptionTrade:
    ts_event_ns: int
    ts_recv_ns: int
    source: EventSource
    underlying: str  # "SPY"
    option_symbol: str  # "O:SPY251216C00676000"
    exp_date: str  # "2025-12-16" (ISO format YYYY-MM-DD)
    strike: float  # 676.0
    right: str  # "C" or "P"
    price: float
    size: int
    opt_bid: Optional[float] = None
    opt_ask: Optional[float] = None
    aggressor: Aggressor = Aggressor.MID
    conditions: Optional[List[int]] = None
    seq: Optional[int] = None
```

**Vendor Ticker Format** (PLAN.md Â§11.1):
```
O:SPY251216C00676000
â”‚ â”‚  â”‚      â”‚ â”‚
â”‚ â”‚  â”‚      â”‚ â””â”€ 8-digit strike (676000 / 1000 = 676.0)
â”‚ â”‚  â”‚      â””â”€â”€â”€ C = Call, P = Put
â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ YYMMDD expiration (251216 = 2025-12-16)
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Underlying (SPY)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ O: prefix (option)
```

**Parsing Logic** (`stream_ingestor.py` lines 72-79):
```python
suffix = ticker[-15:]  # Last 15 chars: YYMMDDCXXXXXXXX
exp_yy = suffix[:2]
exp_mm = suffix[2:4]
exp_dd = suffix[4:6]
right = suffix[6]
strike_str = suffix[7:]
strike = float(strike_str) / 1000.0
exp_date = f"20{exp_yy}-{exp_mm}-{exp_dd}"
```

---

#### 5.2.4 FuturesTrade

**Schema**: `futures.trades.v1`  
**NATS Subject**: `market.futures.trades`  
**Source**: Databento DBN files (GLBX.MDP3 dataset)

```python
@dataclass
class FuturesTrade:
    ts_event_ns: int  # Already in nanoseconds
    ts_recv_ns: int
    source: EventSource  # EventSource.DIRECT_FEED
    symbol: str  # "ES" (continuous front month)
    price: float  # Fixed-point to float: record.price / 1e9
    size: int
    aggressor: Aggressor  # Derived from record.side ('A'/'B'/'N')
    exchange: Optional[str] = "CME"
    conditions: Optional[List[int]] = None
    seq: Optional[int] = None
```

**Aggressor Mapping** (PLAN.md Â§11.3):
- `'B'` (bid=buy aggressor) â†’ `Aggressor.BUY`
- `'A'` (ask=sell aggressor) â†’ `Aggressor.SELL`
- `'N'` (none) â†’ `Aggressor.MID`

---

#### 5.2.5 MBP10

**Schema**: `futures.mbp10.v1`  
**NATS Subject**: `market.futures.mbp10`  
**Source**: Databento DBN files (GLBX.MDP3 MBP-10 schema)

```python
@dataclass
class BidAskLevel:
    bid_px: float
    bid_sz: int
    ask_px: float
    ask_sz: int

@dataclass
class MBP10:
    ts_event_ns: int
    ts_recv_ns: int
    source: EventSource
    symbol: str
    levels: List[BidAskLevel]  # Exactly 10 levels
    is_snapshot: bool = False
    seq: Optional[int] = None
```

**Critical**: MBP-10 is used for ES futures L2 barrier physics (PLAN.md Â§5.1.1). Each update contains **top 10 price levels** per side.

---

## 6. NATS Subject Contracts

All NATS subjects follow the pattern: `<domain>.<asset_class>.<event_type>`

| Subject | Event Type | Producer | Consumers | Retention |
|---------|------------|----------|-----------|-----------|
| `market.stocks.trades` | StockTrade | Ingestor | Core, Lake | 24h |
| `market.stocks.quotes` | StockQuote | Ingestor | Core, Lake | 24h |
| `market.options.trades` | OptionTrade | Ingestor | Core, Lake | 24h |
| `market.futures.trades` | FuturesTrade | Ingestor | Core, Lake | 24h |
| `market.futures.mbp10` | MBP10 | Ingestor | Core, Lake | 24h |

**Stream Configuration** (`bus.py` lines 48-61):
```python
StreamConfig(
    name="MARKET_DATA",
    subjects=["market.*", "market.*.*"],
    retention=RetentionPolicy.LIMITS,
    max_age=24 * 60 * 60,  # 24 hours
    storage="file"  # Persistent (survives NATS restart)
)
```

---

## 7. Vendor Integration

### 7.1 Polygon WebSocket (Live Feeds)

**Documentation**: [Massive WebSocket Docs](https://massive.com/docs/websocket) (Polygon legacy name)

**Endpoints**:
- Stocks: `wss://socket.massive.com/stocks`
- Options: `wss://socket.massive.com/options`

**Authentication**: API key from `POLYGON_API_KEY` environment variable.

**Library**: `polygon-api-client` Python package

**Connection Pattern** (`stream_ingestor.py` lines 34-48):
```python
# Options Client (for option trades)
self.client = WebSocketClient(
    api_key=self.api_key,
    market='options',
    subscriptions=[],  # Dynamic via StrikeManager
    verbose=False
)

# Stocks Client (for SPY trades + quotes)
self.stock_client = WebSocketClient(
    api_key=self.api_key,
    market='stocks',
    subscriptions=["T.SPY", "Q.SPY"],
    verbose=False
)
```

**Message Handling**:
- `handle_msg_async()`: Options trades â†’ OptionTrade events
- `handle_stock_msg_async()`: Stock trades/quotes â†’ StockTrade/StockQuote events

**Dynamic Strike Management** (`stream_ingestor.py` lines 124-127):
```python
if self.strike_manager.should_update(price):
    add, remove = self.strike_manager.get_target_strikes(price)
    self.update_subs(add, remove)
```

Uses `StrikeManager` from `src/core/strike_manager.py` to maintain option subscriptions within `Â±STRIKE_RANGE` of current SPY spot.

---

### 7.2 Databento DBN Files (Historical Data)

**Dataset**: `GLBX.MDP3` (CME Globex MDP 3.0)  
**Documentation**: [Databento GLBX.MDP3](https://databento.com/datasets/GLBX.MDP3)

**Schemas**:
- `trades`: Tick-by-tick ES futures trades
- `mbp-10`: Market-by-price L2 (top 10 depth updates)

**Symbology**: Continuous front month contract `ES.c.0` (auto-rolls per Databento rules)

**File Location** (per `dbn_ingestor.py` lines 74-74):
```
project_root/
  dbn-data/
    trades/
      glbx-mdp3-20251214.trades.dbn
      glbx-mdp3-20251215.trades.dbn
      ...
      symbology.json  # Instrument ID â†’ Symbol mapping
      metadata.json
    MBP-10/
      glbx-mdp3-20251214.mbp-10.dbn
      glbx-mdp3-20251215.mbp-10.dbn
      ...
      symbology.json
```

**Iterator Pattern**: All DBN reading uses **streaming iterators** to avoid loading entire files (important for MBP-10 which can be 10GB+).

---

## 8. Replay System

### 8.1 Architecture

The replay system consists of two components:

1. **DBNIngestor** (`dbn_ingestor.py`): Low-level DBN file reader
2. **ReplayPublisher** (`replay_publisher.py`): High-level NATS publisher with speed control

### 8.2 Replay Speed Control

Replay speed is controlled via event-time deltas (not wall-clock sleep):

```python
# replay_publisher.py lines 138-147
event_delta_ns = event.ts_event_ns - prev_event_ns
wall_delay_sec = (event_delta_ns / 1e9) / self.replay_speed

# Examples:
# replay_speed = 0.0  â†’ wall_delay_sec = 0 (fast as possible)
# replay_speed = 1.0  â†’ wall_delay_sec = event_delta_sec (realtime)
# replay_speed = 2.0  â†’ wall_delay_sec = event_delta_sec / 2 (2x speed)
```

**Cap**: Maximum delay is capped at 5 seconds to avoid huge gaps from market closures.

### 8.3 Time Range Filtering

All DBN readers support time range filtering:

```python
# Read trades from a specific date with time filter
for trade in dbn_ingestor.read_trades(
    date="2025-12-16",
    start_ns=1734364800000000000,  # 2025-12-16 14:30:00 UTC
    end_ns=1734368400000000000     # 2025-12-16 15:30:00 UTC
):
    # Process trade
```

### 8.4 Merged Stream Replay

`ReplayPublisher.replay_date()` merges trades and MBP-10 into a single time-ordered stream:

```python
# replay_publisher.py lines 108-118
events = []
for trade in dbn_ingestor.read_trades(date, start_ns, end_ns):
    events.append(("trade", trade))
for mbp in dbn_ingestor.read_mbp10(date, start_ns, end_ns):
    events.append(("mbp10", mbp))

# Sort by event time
events.sort(key=lambda x: x[1].ts_event_ns)
```

**Critical**: This ensures correct event-time ordering across schemas, which is essential for deterministic replay.

---

## 9. Class Reference

### 9.1 StreamIngestor

**File**: `stream_ingestor.py`  
**Purpose**: Live WebSocket adapter for Polygon feeds

#### Constructor

```python
def __init__(
    self, 
    api_key: str, 
    bus: NATSBus, 
    strike_manager: StrikeManager,
    queue: Optional[asyncio.Queue] = None  # Backward compat (deprecated)
)
```

**Parameters**:
- `api_key`: Polygon API key from environment
- `bus`: NATS bus instance for publishing
- `strike_manager`: Dynamic strike management for option subscriptions
- `queue`: **Deprecated** â€” backward compatibility for transition; will be removed

#### Methods

##### `run_async()`

```python
async def run_async(self) -> None
```

Main entry point. Connects to both Polygon WebSocket clients (stocks + options) and runs message handlers concurrently.

##### `handle_msg_async(msgs: List[WebSocketMessage])`

```python
async def handle_msg_async(self, msgs: List[WebSocketMessage]) -> None
```

Handles **option trades**:
1. Parse option ticker (O:SPY...)
2. Extract expiration, strike, right
3. Normalize to `OptionTrade` event
4. Publish to `market.options.trades`

##### `handle_stock_msg_async(msgs: List[WebSocketMessage])`

```python
async def handle_stock_msg_async(self, msgs: List[WebSocketMessage]) -> None
```

Handles **stock trades and quotes**:
1. Differentiate trade vs quote by checking for `bid_price` field
2. Normalize to `StockTrade` or `StockQuote`
3. Trigger dynamic strike updates on price moves
4. Publish to `market.stocks.trades` or `market.stocks.quotes`

##### `update_subs(add: List[str], remove: List[str])`

```python
def update_subs(self, add: List[str], remove: List[str]) -> None
```

Update option subscriptions dynamically as SPY price moves.

---

### 9.2 DBNIngestor

**File**: `dbn_ingestor.py`  
**Purpose**: Databento DBN file reader with streaming iterators

#### Constructor

```python
def __init__(self, dbn_data_root: Optional[str] = None)
```

**Parameters**:
- `dbn_data_root`: Root directory containing DBN files (defaults to `project_root/dbn-data/`)

#### Methods

##### `discover_files(schema: Optional[str] = None) -> List[DBNFileInfo]`

Discover available DBN files. Returns metadata for all files (or filtered by schema).

##### `read_trades(date, start_ns, end_ns) -> Iterator[FuturesTrade]`

```python
def read_trades(
    self,
    date: Optional[str] = None,
    start_ns: Optional[int] = None,
    end_ns: Optional[int] = None
) -> Iterator[FuturesTrade]
```

**Yields**: Normalized `FuturesTrade` events

**Critical**: Uses **iterator pattern** (yields per record) to avoid loading entire file into memory.

##### `read_mbp10(date, start_ns, end_ns) -> Iterator[MBP10]`

```python
def read_mbp10(
    self,
    date: Optional[str] = None,
    start_ns: Optional[int] = None,
    end_ns: Optional[int] = None
) -> Iterator[MBP10]
```

**Yields**: Normalized `MBP10` events (10 bid/ask levels)

**Memory Efficiency**: MBP-10 files can be 10GB+ per day. Iterator pattern is critical for handling large files.

##### `get_time_range(date: str, schema: str) -> Tuple[Optional[int], Optional[int]]`

Get min/max `ts_event_ns` for a date (useful for UI time pickers or sub-session filtering).

---

### 9.3 ReplayPublisher

**File**: `replay_publisher.py`  
**Purpose**: Publish DBN data to NATS at configurable speed

#### Constructor

```python
def __init__(
    self,
    bus: NATSBus,
    dbn_ingestor: DBNIngestor,
    replay_speed: float = 1.0
)
```

**Parameters**:
- `bus`: NATS bus instance
- `dbn_ingestor`: DBN file reader
- `replay_speed`: 0.0 = fast as possible, 1.0 = realtime, 2.0 = 2x speed

#### Methods

##### `replay_date(date, start_ns, end_ns, include_trades, include_mbp10)`

```python
async def replay_date(
    self,
    date: str,
    start_ns: Optional[int] = None,
    end_ns: Optional[int] = None,
    include_trades: bool = True,
    include_mbp10: bool = True
) -> None
```

Replay all data for a specific date. Merges trades + MBP-10 into a single time-ordered stream.

##### `replay_continuous(dates, start_ns, end_ns)`

```python
async def replay_continuous(
    self,
    dates: Optional[List[str]] = None,
    start_ns: Optional[int] = None,
    end_ns: Optional[int] = None
) -> None
```

Replay multiple dates sequentially.

---

## 10. Entry Points

### 10.1 Live Ingestion Service

**File**: `main.py`  
**Command**: 
```bash
export POLYGON_API_KEY="your_key_here"
uv run python -m src.ingestor.main
```

**Environment Variables**:
- `POLYGON_API_KEY` (required): Polygon API key
- `NATS_URL` (optional): NATS server URL (default: `nats://localhost:4222`)

**Output**:
```
============================================================
ğŸš€ INGESTOR SERVICE
============================================================
âœ… Ingestor initialized
ğŸ“¡ Publishing to NATS at nats://localhost:4222
ğŸ¯ Subjects: market.stocks.*, market.options.*
============================================================
ğŸ”Œ StreamIngestor: Connecting to Polygon Options + Stocks...
```

**Shutdown**: `Ctrl+C` (graceful shutdown, closes NATS connection)

---

### 10.2 Replay Publisher Service

**File**: `replay_publisher.py`  
**Command**:
```bash
export REPLAY_SPEED=1.0  # 1x realtime
export REPLAY_DATE=2025-12-16  # Single date (or omit for all dates)
uv run python -m src.ingestor.replay_publisher
```

**Environment Variables**:
- `REPLAY_SPEED` (optional): Replay speed multiplier (default: 1.0)
- `REPLAY_DATE` (optional): Single date to replay (YYYY-MM-DD), or omit for all available dates
- `NATS_URL` (optional): NATS server URL

**Output**:
```
============================================================
ğŸ¬ REPLAY PUBLISHER
============================================================
ğŸ“ Found 6 days of data:
   - 2025-12-14
   - 2025-12-15
   ...
ğŸ¬ Starting replay for 2025-12-16
   Speed: 1.0x
   Trades: True, MBP-10: True
  ğŸ“Š Loading trades...
  ğŸ“ˆ Loading MBP-10...
  âœ… Loaded 1,234,567 events
  ğŸ¯ Publishing to NATS...
    Progress: 10000 events (5432 trades, 4568 mbp10) @ 1.02x
```

---

### 10.3 Development Test

**File**: `test_stream.py`  
**Purpose**: Simple WebSocket connection test (no NATS, just print messages)

**Command**:
```bash
export POLYGON_API_KEY="your_key_here"
uv run python backend/src/ingestor/test_stream.py
```

**Use Case**: Verify Polygon API key and WebSocket connectivity before running full service.

---

## 11. Dependencies

### 11.1 Internal Dependencies (Within Spymaster)

| Module | Usage | Critical Classes/Functions |
|--------|-------|---------------------------|
| `src/common/event_types` | Event dataclasses | `StockTrade`, `StockQuote`, `OptionTrade`, `FuturesTrade`, `MBP10`, `EventSource`, `Aggressor` |
| `src/common/bus` | NATS publishing | `NATSBus.publish()` |
| `src/common/config` | Configuration | `CONFIG.NATS_URL`, `CONFIG.REPLAY_SPEED` |
| `src/core/strike_manager` | Dynamic strikes | `StrikeManager.should_update()`, `get_target_strikes()` |

### 11.2 External Dependencies (Python Packages)

| Package | Version | Purpose |
|---------|---------|---------|
| `polygon-api-client` | Latest | Polygon WebSocket client |
| `databento` | Latest | DBN file reading |
| `databento-dbn` | Latest | DBN record types (`TradeMsg`, `MBP10Msg`) |
| `nats-py` | Latest | NATS JetStream client |

**Install**:
```bash
uv add polygon-api-client databento databento-dbn nats-py
```

---

## 12. Testing and Validation

### 12.1 Unit Test Coverage

Currently, the ingestor module does **not have dedicated unit tests**. Testing is performed via:
1. Integration tests (`backend/tests/test_e2e_replay.py`)
2. Manual validation using `test_stream.py`

### 12.2 Integration Test Checklist

When modifying this module, verify:

- [ ] **Live ingestion**: Run `main.py` with valid API key, verify NATS messages
- [ ] **Replay**: Run `replay_publisher.py`, verify event ordering and speed
- [ ] **Event normalization**: Check `ts_event_ns`, `ts_recv_ns`, `source` fields
- [ ] **Dynamic strikes**: Verify option subscriptions update as SPY moves
- [ ] **Time filtering**: Test replay with `start_ns`/`end_ns` filters
- [ ] **NATS persistence**: Kill/restart NATS, verify events are not lost (24h retention)

### 12.3 Validation Queries

Check published events in NATS:
```bash
# Subscribe to all market data
nats sub "market.>"

# Check stream info
nats stream info MARKET_DATA

# Check consumer lag
nats consumer info MARKET_DATA <consumer_name>
```

---

## 13. Operational Notes

### 13.1 Performance Characteristics

**Live Ingestion**:
- **Latency**: ~5-15ms from Polygon exchange timestamp to NATS publish (on M4 Mac)
- **Throughput**: Handles 10k+ events/sec (SPY option flow during 0DTE expiration)
- **Memory**: ~50-100MB resident (steady state with 100+ option subscriptions)

**Replay**:
- **Fast mode (0x)**: ~100k events/sec on M4 Mac (limited by JSON serialization + NATS)
- **Realtime mode (1x)**: Matches wall clock (e.g., 1 hour of data = 1 hour of replay)
- **Memory**: ~200-500MB for large MBP-10 file loading (iterator pattern keeps it bounded)

### 13.2 Failure Modes and Recovery

| Failure | Behavior | Recovery |
|---------|----------|----------|
| Polygon disconnect | WebSocket client auto-reconnects | Automatic (may lose ~1-2 seconds of data) |
| NATS disconnect | Publish raises exception, service crashes | Restart service (NATS retains last 24h) |
| DBN file missing | `discover_files()` returns empty list | Check `dbn-data/` directory |
| Invalid API key | Service exits with error | Set `POLYGON_API_KEY` environment variable |
| Out of memory (large DBN) | Iterator pattern prevents OOM | N/A (already handled) |

### 13.3 Monitoring

Key metrics to monitor:

1. **Message rate**: `nats stream info MARKET_DATA` (check `msgs` and `bytes` fields)
2. **Consumer lag**: Check if Lake/Core services are keeping up with Ingestor
3. **Replay speed accuracy**: Compare `ReplayStats.actual_speed()` vs target
4. **Error logs**: Watch for normalization failures (invalid tickers, missing fields)

### 13.4 Cost and Rate Limits

**Polygon**:
- **WebSocket connections**: 1 connection per API key per market (stocks + options = 2 connections)
- **Rate limits**: No explicit limit on WebSocket messages, but subscriptions may have limits (check plan)
- **Cost**: Based on subscription tier (stocks + options quotes/trades required)

**NATS JetStream**:
- **Storage**: 24h retention with file backing (~5-10GB/day for SPY + ES data)
- **Memory**: Minimal (NATS is highly optimized)

---

## Appendix A: PLAN.md Cross-References

| Topic | PLAN.md Section |
|-------|-----------------|
| System architecture | Â§1 (System architecture "Snap Engine") |
| Message envelope contract | Â§2.1 (Message envelope) |
| Storage schemas | Â§2.4 (Storage schemas) |
| Vendor contracts (Polygon) | Â§11.1 (Massive WebSocket) |
| Vendor contracts (Databento) | Â§11.3 (Databento ES futures) |
| Phase 2 architecture | Â§13 (Phase 2 Agent assignments) |

---

## Appendix B: Quick Reference

### Event Type â†’ NATS Subject Mapping

```
StockTrade     â†’  market.stocks.trades
StockQuote     â†’  market.stocks.quotes
OptionTrade    â†’  market.options.trades
FuturesTrade   â†’  market.futures.trades
MBP10          â†’  market.futures.mbp10
```

### Time Unit Conversions

```python
# Polygon uses milliseconds
ts_event_ns = polygon_timestamp_ms * 1_000_000

# Databento uses nanoseconds (no conversion)
ts_event_ns = dbn_record.ts_event

# Current time in nanoseconds
ts_recv_ns = time.time_ns()
```

### Replay Speed Examples

```bash
# Fast as possible (no delays)
export REPLAY_SPEED=0

# Realtime (1 second of data = 1 second of replay)
export REPLAY_SPEED=1.0

# 10x speed (1 second of data = 0.1 seconds of replay)
export REPLAY_SPEED=10.0

# Half speed (1 second of data = 2 seconds of replay)
export REPLAY_SPEED=0.5
```

---

**Document Version**: 1.0  
**Last Updated**: 2025-12-22  
**Maintainer**: Phase 2 Agent A  
**Status**: Complete (Phase 2 implementation)

