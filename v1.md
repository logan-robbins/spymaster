

### What you have (from `PENTAVIEW.md`, `PENTAVIEW_UI.md`, and `demo/`)
- **Pentaview’s “clock”**:
  - **State table (Stage 16)** is **30-second cadence**.
  - **Pentaview stream bars** are **2-minute bars** computed by **resampling the 30s state**.
  - UI doc explicitly anticipates **30s updates** that are **aggregated to 2-min bars**.
- **What “training Pentaview” means in this repo**:
  - **Normalization stats** (median/MAD or mean/std by time bucket) → `data/gold/streams/normalization/current.json`
  - **Projection models** (quantile polynomial regression predicting 20-min-ahead curves) trained from `stream_bars.parquet`
- **`demo/`** is a **standalone replay UI** that:
  - Replays a day of **2-minute candles**
  - Updates the “forward projection” **at each bar close**
  - Maintains a **2-overlay system** (current projection + accumulated historical band)
  - It is **not wired to Pentaview** yet, but it’s the right UI pattern for “projection overlays”.

---

### Step-by-step: Train Pentaview on 2025-11-15 → 2025-12-15
All Python commands should run from `backend/` using `uv`.

#### 0) Define constants (agent should keep these explicit)
- **canonical_version**: `3.1.0`
- **train_start**: `2025-11-15`
- **train_end**: `2025-12-15`
- **dataset_version tag**: e.g. `v20251115_20251215`

#### 1) Ensure Stage 16 state tables exist for the training range
Pentaview depends on **Stage 16 state tables** being present at:
- `backend/data/silver/state/es_level_state/version=3.1.0/date=YYYY-MM-DD/state.parquet`

If missing, generate them by running the ES pipeline over the date range:

```bash
cd backend
uv run python -m scripts.run_pipeline \
  --start 2025-11-15 \
  --end 2025-12-15 \
  --canonical-version 3.1.0 \
  --checkpoint-dir data/checkpoints
```

- **Fail-fast check**: If the pipeline errors with “No ES trades found …”, you don’t have Bronze data for that date.

#### 2) Compute normalization stats (this is “training step 1”)
This must produce `backend/data/gold/streams/normalization/current.json` (Pentaview uses `current.json` by default).

```bash
cd backend
uv run python -m scripts.compute_stream_normalization \
  --lookback-days 30 \
  --end-date 2025-12-15 \
  --canonical-version 3.1.0 \
  --output-name current
```

- **Why 30**: `end_date - 30 days = 2025-11-15`, matching your requested window.

#### 3) Generate Pentaview stream bars for the training range
This reads the Stage 16 state tables and writes:
- `backend/data/gold/streams/pentaview/version=3.1.0/date=YYYY-MM-DD/stream_bars.parquet`

```bash
cd backend
uv run python -m scripts.run_pentaview_pipeline \
  --date 2025-11-15 \
  --start 2025-11-15 \
  --end 2025-12-15 \
  --canonical-version 3.1.0
```

- **Important quirk**: `scripts/run_pentaview_pipeline.py` requires `--date` even when using `--start/--end`, so pass `--date` equal to `--start`.

(Optional sanity gate per-day):

```bash
cd backend
uv run python -m scripts.validate_pentaview --date 2025-12-15 --canonical-version 3.1.0
```

#### 4) Build the projection training dataset
This creates `.npz` samples under:
- `backend/data/gold/training/projection_samples/projection_samples_sigma_…_<version>.npz`

```bash
cd backend
uv run python -m scripts.build_projection_dataset \
  --start 2025-11-15 \
  --end 2025-12-15 \
  --canonical-version 3.1.0 \
  --streams sigma_p,sigma_m,sigma_f,sigma_b,sigma_r \
  --version v20251115_20251215
```

#### 5) Train the projection models
This writes models to:
- `backend/data/ml/projection_models/projection_sigma_…_<version>.joblib`

```bash
cd backend
uv run python -m scripts.train_projection_models \
  --stream all \
  --version v20251115_20251215 \
  --epochs 200 \
  --learning-rate 0.05 \
  --max-depth 6
```

---

### Step-by-step: Replay 2025-12-18 from RTH as 2-minute candles + projection overlay
There are two separate things you’re trying to “replay”:
- **Price candles**: 2-minute OHLCV
- **Pentaview overlay**: stream bars (2-min) + projected curves (next 20 min)

#### 6) Prepare 2025-12-18 artifacts (recommended even if you do NATS replay)
Generate the state table + streams for the replay date:

```bash
cd backend
uv run python -m scripts.run_pipeline --date 2025-12-18 --canonical-version 3.1.0 --checkpoint-dir data/checkpoints
uv run python -m scripts.run_pentaview_pipeline --date 2025-12-18 --canonical-version 3.1.0
```

This guarantees you have:
- **30s state table** for precise “every 30s” stepping (if desired)
- **2-min stream bars** for stable chart alignment and model inputs

#### 7) How the replay loop should work (agent instructions)
At runtime, maintain **two clocks**:

- **Clock A (30s)**: state ticks (`state_df` rows, 30s cadence)
- **Clock B (2min)**: candle/stream bars (every 2 minutes)

For each new **30s tick**:
- **Update the in-progress 2-min candle** (if your chart supports “live candle updates”).
- **Update the in-progress 2-min stream bar** by taking “last known state within the current 2-min bin”.

For each **2-min boundary (bar close)**:
- **Finalize** the 2-min candle
- **Finalize** the 2-min stream bar (this is the value that matches training)
- **Run projection inference** and update the “forward projection” overlay

#### 8) Should you call inference every 30 seconds?
**Recommendation: run inference on 2-minute bar close (every 2 minutes)**, because:
- The projection models are trained on **2-minute bars**.
- It produces stable overlays and avoids “churn” from partially-formed bars.

If you want the UI to feel more “live”, you *can* do this hybrid:
- **Every 30s**: recompute a *provisional* current stream value and refresh the **current (bright) projection**.
- **Every 2min**: “commit” the projection by advancing the history and extending the **historical (faded) band** (the same 2-overlay pattern your `demo/` implements).

That gives you smooth responsiveness without turning the chart into a jittery scribble.

#### 9) What the overlay update should look like (match `demo/`’s 2-overlay pattern)
- **Overlay 1 (bright)**: the latest projection curves/bands (q10/q50/q90) extending ~20 minutes into the future.
- **Overlay 2 (faded)**: the accumulated historical band showing how projections evolved.

Only “append” to the historical band when a **2-min bar closes**.

#### 10) Practical gotchas the agent must account for
- **Minimum history**: Projection inference needs **20 prior 2-min bars** (≈ 40 minutes) per level before it can run correctly.
- **Starting replay at RTH vs premarket**:
  - If you truly start ingest at **09:30 only**, you may lose **PM_HIGH/PM_LOW** context and SMA warmup.
  - Best practice: **warm up from premarket**, but **start rendering the chart at 09:30**.
- **Repo scope**: The batch pipeline’s v1 RTH scope is “first hours” (not full 9:30–16:00), so ensure your replay expectations match that.

---

Summary:
- Modified no files; based guidance on existing `scripts.*` training pipeline and Pentaview UI contract
- Identified recommended inference cadence: project on **2-min closes**, optionally refresh “current” projection every **30s** as provisional
- Verified repo entrypoints/paths by reading the Pentaview scripts, pipeline stages, and replay components